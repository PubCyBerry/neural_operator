{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particle Swarm Optimizer \n",
    "### code from scikit-opt (https://github.com/guofei9987/scikit-opt/tree/master/sko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import multiprocessing\n",
    "from pathos.pools import ProcessPool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.ones((64, 100)) # input signal shape from matlab\n",
    "tar = np.zeros_like(inp) # target signal shape from matlab\n",
    "learnable_params = np.ones(100) # parameters from S-Functions\n",
    "epoch = 50\n",
    "\n",
    "def s_function(inp, params): # S-Function\n",
    "    return inp * params\n",
    "\n",
    "# sample = s_function(inp, learnable_params)\n",
    "# print(sample.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo : set upper bound and lower bound different for each parameters\n",
    "\n",
    "class PSO():\n",
    "    \n",
    "    def __init__(self, func, n_dim=None, pop=40, max_iter=150, lb=-1e5, ub=1e5, w=0.8, c1=0.5, c2=0.5,\n",
    "                 constraint_eq=tuple(), constraint_ueq=tuple(), verbose=False\n",
    "                 , dim=None, data = tuple()):\n",
    "\n",
    "        n_dim = n_dim or dim  # support the earlier version\n",
    "\n",
    "        self.func = func\n",
    "        self.w = w  # inertia\n",
    "        self.cp, self.cg = c1, c2  # parameters to control personal best, global best respectively\n",
    "        self.pop = pop  # number of particles\n",
    "        self.n_dim = n_dim  # dimension of particles, which is the number of variables of func\n",
    "        self.max_iter = max_iter  # max iter\n",
    "        self.verbose = verbose  # print the result of each iter or not\n",
    "        # self.input = data[0]\n",
    "        self.input = np.tile(data[0], (self.pop, 1, 1))\n",
    "        self.target = data[1]\n",
    "        # self.target = np.tile(data[1], (self.pop, 1, 1))\n",
    "\n",
    "        self.lb, self.ub = np.array(lb) * np.ones(self.n_dim), np.array(ub) * np.ones(self.n_dim)\n",
    "        assert self.n_dim == len(self.lb) == len(self.ub), 'dim == len(lb) == len(ub) is not True'\n",
    "        assert np.all(self.ub > self.lb), 'upper-bound must be greater than lower-bound'\n",
    "\n",
    "        self.has_constraint = bool(constraint_ueq)\n",
    "        self.constraint_ueq = constraint_ueq\n",
    "        self.is_feasible = np.array([True] * pop)\n",
    "\n",
    "        self.X = np.random.uniform(low=self.lb, high=self.ub, size=(self.pop, self.n_dim))\n",
    "        v_high = self.ub - self.lb\n",
    "        self.V = np.random.uniform(low=-v_high, high=v_high, size=(self.pop, self.n_dim))  # speed of particles\n",
    "        self.Y = self.cal_y()  # y = f(x) for all particles\n",
    "        self.pbest_x = self.X.copy()  # personal best location of every particle in history\n",
    "        self.pbest_y = np.array([[np.inf]] * pop)  # best image of every particle in history\n",
    "        self.gbest_x = self.pbest_x.mean(axis=0).reshape(1, -1)  # global best location for all particles\n",
    "        self.gbest_y = np.inf  # global best y for all particles\n",
    "        self.gbest_y_hist = []  # gbest_y of every iteration\n",
    "        self.update_gbest()\n",
    "\n",
    "        # record verbose values\n",
    "        self.record_mode = True\n",
    "        self.record_value = {'X': [], 'V': [], 'Y': []}\n",
    "        self.best_x, self.best_y = self.gbest_x, self.gbest_y  # history reasons, will be deprecated\n",
    "\n",
    "    def check_constraint(self, x):\n",
    "        # gather all unequal constraint functions\n",
    "        for constraint_func in self.constraint_ueq:\n",
    "            if constraint_func(x) > 0:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def update_V(self):\n",
    "        r1 = np.random.rand(self.pop, self.n_dim)\n",
    "        r2 = np.random.rand(self.pop, self.n_dim)\n",
    "        self.V = self.w * self.V + \\\n",
    "                 self.cp * r1 * (self.pbest_x - self.X) + \\\n",
    "                 self.cg * r2 * (self.gbest_x - self.X)\n",
    "\n",
    "    def update_X(self):\n",
    "        self.X = self.X + self.V\n",
    "        self.X = np.clip(self.X, self.lb, self.ub)\n",
    "\n",
    "    def cal_y(self):\n",
    "        # calculate y for every x in X\n",
    "        # self.Y = self.func(self.X).reshape(-1, 1)\n",
    "        # self.Y = np.sum(np.abs(self.func(self.input, self.X).flatten() - self.target.flatten())) / len(self.target)\n",
    "\n",
    "        p = ProcessPool(nodes=os.cpu_count())\n",
    "        output = p.map(self.func, self.input, self.X)\n",
    "        self.Y = np.expand_dims(np.array([np.mean(np.abs(self.target - i)) for i in output]), axis=1)\n",
    "\n",
    "        # output = []\n",
    "        # for idx in range(len(self.X)):\n",
    "        #     p = multiprocessing.Process(target=self.func, args=(self.X[idx], self.input[idx]))\n",
    "        #     p.start()\n",
    "        #     output.append(p)\n",
    "        # for p in output:\n",
    "        #     p.join()\n",
    "        # self.Y = np.expand_dims(np.array([np.mean(np.abs(self.target - i)) for i in output]), axis=1)\n",
    "\n",
    "        return self.Y\n",
    "\n",
    "\n",
    "\n",
    "    def update_pbest(self):\n",
    "        '''\n",
    "        personal best\n",
    "        :return:\n",
    "        '''\n",
    "        self.need_update = self.pbest_y > self.Y\n",
    "        for idx, x in enumerate(self.X):\n",
    "            if self.need_update[idx]:\n",
    "                self.need_update[idx] = self.check_constraint(x)\n",
    "\n",
    "        self.pbest_x = np.where(self.need_update, self.X, self.pbest_x)\n",
    "        self.pbest_y = np.where(self.need_update, self.Y, self.pbest_y)\n",
    "\n",
    "    def update_gbest(self):\n",
    "        '''\n",
    "        global best\n",
    "        :return:\n",
    "        '''\n",
    "        idx_min = self.pbest_y.argmin()\n",
    "        if self.gbest_y > self.pbest_y[idx_min]:\n",
    "            self.gbest_x = self.X[idx_min, :].copy()\n",
    "            self.gbest_y = self.pbest_y[idx_min]\n",
    "\n",
    "    def recorder(self):\n",
    "        if not self.record_mode:\n",
    "            return\n",
    "        self.record_value['X'].append(self.X)\n",
    "        self.record_value['V'].append(self.V)\n",
    "        self.record_value['Y'].append(self.Y)\n",
    "\n",
    "    def run(self, max_iter=None, precision=None, N=20):\n",
    "        '''\n",
    "        precision: None or float\n",
    "            If precision is None, it will run the number of max_iter steps\n",
    "            If precision is a float, the loop will stop if continuous N difference between pbest less than precision\n",
    "        N: int\n",
    "        '''\n",
    "        self.max_iter = max_iter or self.max_iter\n",
    "        c = 0\n",
    "        for iter_num in range(self.max_iter):\n",
    "            self.update_V()\n",
    "            self.recorder()\n",
    "            self.update_X()\n",
    "            self.cal_y()\n",
    "            self.update_pbest()\n",
    "            self.update_gbest()\n",
    "            if precision is not None:\n",
    "                tor_iter = np.amax(self.pbest_y) - np.amin(self.pbest_y)\n",
    "                if tor_iter < precision:\n",
    "                    c = c + 1\n",
    "                    if c > N:\n",
    "                        break\n",
    "                else:\n",
    "                    c = 0\n",
    "            if self.verbose and ((iter_num % (self.max_iter // 10) == 0) or (iter_num+1 == self.max_iter)):\n",
    "                print('Iter: {}, Best fit: {}'.format(iter_num, self.gbest_y))\n",
    "                # print('Iter: {}, Best fit: {} at {}'.format(iter_num, self.gbest_y, self.gbest_x))\n",
    "\n",
    "            self.gbest_y_hist.append(self.gbest_y)\n",
    "        self.best_x, self.best_y = self.gbest_x, self.gbest_y\n",
    "        return self.best_x, self.best_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Best fit: [1.15044116]\n",
      "Iter: 10, Best fit: [0.82307478]\n",
      "Iter: 20, Best fit: [0.70760319]\n",
      "Iter: 30, Best fit: [0.60291284]\n",
      "Iter: 40, Best fit: [0.52875411]\n",
      "Iter: 50, Best fit: [0.47711216]\n",
      "Iter: 60, Best fit: [0.44518207]\n",
      "Iter: 70, Best fit: [0.42745285]\n",
      "Iter: 80, Best fit: [0.41032155]\n",
      "Iter: 90, Best fit: [0.39881566]\n",
      "Iter: 99, Best fit: [0.39171101]\n"
     ]
    }
   ],
   "source": [
    "pso = PSO(func=s_function, n_dim=len(learnable_params), pop=300, max_iter=100, lb=-2, ub=2, w=0.75, c1=1, c2=1, data=(inp, tar), verbose=True)\n",
    "learned_params, best_loss = pso.run(max_iter=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Generation of PSO\n",
    "class SGPSO():\n",
    "    \n",
    "    def __init__(self, func, n_dim=None, pop=40, max_iter=150, lb=-1e5, ub=1e5, w=0.8, c1=0.5, c2=0.5, c3=0.5,\n",
    "                 constraint_eq=tuple(), constraint_ueq=tuple(), verbose=False\n",
    "                 , dim=None, data = tuple(), p_interval = 0):\n",
    "\n",
    "        n_dim = n_dim or dim  # support the earlier version\n",
    "\n",
    "        self.func = func\n",
    "        self.w = w  # inertia\n",
    "        self.cp, self.cg, self.cc = c1, c2, c3 # parameters to control personal best, global best respectively\n",
    "        self.pop = pop  # number of particles\n",
    "        self.n_dim = n_dim  # dimension of particles, which is the number of variables of func\n",
    "        self.max_iter = max_iter  # max iter\n",
    "        self.verbose = verbose  # print the result of each iter or not\n",
    "        # self.input = data[0]\n",
    "        self.input = np.tile(data[0], (self.pop, 1, 1))\n",
    "        self.target = data[1]\n",
    "        # self.target = np.tile(data[1], (self.pop, 1, 1))\n",
    "        if not p_interval:\n",
    "            self.p_interval = self.max_iter // 10\n",
    "        else:\n",
    "            self.p_interval = p_interval\n",
    "\n",
    "        self.lb, self.ub = np.array(lb) * np.ones(self.n_dim), np.array(ub) * np.ones(self.n_dim)\n",
    "        assert self.n_dim == len(self.lb) == len(self.ub), 'dim == len(lb) == len(ub) is not True'\n",
    "        assert np.all(self.ub > self.lb), 'upper-bound must be greater than lower-bound'\n",
    "\n",
    "        self.has_constraint = bool(constraint_ueq)\n",
    "        self.constraint_ueq = constraint_ueq\n",
    "        self.is_feasible = np.array([True] * pop)\n",
    "\n",
    "        self.X = np.random.uniform(low=self.lb, high=self.ub, size=(self.pop, self.n_dim))\n",
    "        v_high = self.ub - self.lb\n",
    "        self.V = np.random.uniform(low=-v_high, high=v_high, size=(self.pop, self.n_dim))  # speed of particles\n",
    "        self.Y = self.cal_y()  # y = f(x) for all particles\n",
    "        self.pbest_x = self.X.copy()  # personal best location of every particle in history\n",
    "        self.pbest_y = np.array([[np.inf]] * pop)  # best image of every particle in history\n",
    "        self.gbest_x = self.pbest_x.mean(axis=0).reshape(1, -1)  # global best location for all particles\n",
    "        self.gbest_y = np.inf  # global best y for all particles\n",
    "        self.gbest_y_hist = []  # gbest_y of every iteration\n",
    "        self.update_gbest()\n",
    "\n",
    "        self.centre = np.sum(self.pbest_x, axis=0) / self.pop\n",
    "\n",
    "        # record verbose values\n",
    "        self.record_mode = True\n",
    "        self.record_value = {'X': [], 'V': [], 'Y': []}\n",
    "        self.best_x, self.best_y = self.gbest_x, self.gbest_y  # history reasons, will be deprecated\n",
    "\n",
    "    def check_constraint(self, x):\n",
    "        # gather all unequal constraint functions\n",
    "        for constraint_func in self.constraint_ueq:\n",
    "            if constraint_func(x) > 0:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def update_V(self):\n",
    "        r1 = np.random.rand(self.pop, self.n_dim)\n",
    "        r2 = np.random.rand(self.pop, self.n_dim)\n",
    "        r3 = np.random.rand(self.pop, self.n_dim)\n",
    "        self.V = self.w * self.V + \\\n",
    "                 self.cp * r1 * (self.pbest_x - self.X) + \\\n",
    "                 self.cg * r2 * (self.gbest_x - self.X) + \\\n",
    "                 self.cc * r3 * (self.centre - self.X)\n",
    "\n",
    "    def update_X(self):\n",
    "        self.X = self.X + self.V\n",
    "        self.X = np.clip(self.X, self.lb, self.ub)\n",
    "\n",
    "    def cal_y(self):\n",
    "        p = ProcessPool(nodes=os.cpu_count())\n",
    "        output = p.map(self.func, self.input, self.X)\n",
    "        self.Y = np.expand_dims(np.array([np.mean(np.abs(self.target - i)) for i in output]), axis=1)\n",
    "\n",
    "        return self.Y\n",
    "    \n",
    "    def update_centre(self):\n",
    "        self.centre = np.sum(self.pbest_x, axis=0) / self.pop\n",
    "        return \n",
    "\n",
    "    def update_pbest(self):\n",
    "        '''\n",
    "        personal best\n",
    "        :return:\n",
    "        '''\n",
    "        self.need_update = self.pbest_y > self.Y\n",
    "        for idx, x in enumerate(self.X):\n",
    "            if self.need_update[idx]:\n",
    "                self.need_update[idx] = self.check_constraint(x)\n",
    "\n",
    "        self.pbest_x = np.where(self.need_update, self.X, self.pbest_x)\n",
    "        self.pbest_y = np.where(self.need_update, self.Y, self.pbest_y)\n",
    "\n",
    "    def update_gbest(self):\n",
    "        '''\n",
    "        global best\n",
    "        :return:\n",
    "        '''\n",
    "        idx_min = self.pbest_y.argmin()\n",
    "        if self.gbest_y > self.pbest_y[idx_min]:\n",
    "            self.gbest_x = self.X[idx_min, :].copy()\n",
    "            self.gbest_y = self.pbest_y[idx_min]\n",
    "\n",
    "    def recorder(self):\n",
    "        if not self.record_mode:\n",
    "            return\n",
    "        self.record_value['X'].append(self.X)\n",
    "        self.record_value['V'].append(self.V)\n",
    "        self.record_value['Y'].append(self.Y)\n",
    "\n",
    "    def run(self, max_iter=None, precision=None, N=20, p_interval=0):\n",
    "        '''\n",
    "        precision: None or float\n",
    "            If precision is None, it will run the number of max_iter steps\n",
    "            If precision is a float, the loop will stop if continuous N difference between pbest less than precision\n",
    "        N: int\n",
    "        '''\n",
    "        self.max_iter = max_iter or self.max_iter\n",
    "        if p_interval:\n",
    "            self.p_interval=p_interval\n",
    "        c = 0\n",
    "        for iter_num in range(self.max_iter):\n",
    "            self.update_V()\n",
    "            self.recorder()\n",
    "            self.update_X()\n",
    "            self.cal_y()\n",
    "            self.update_pbest()\n",
    "            self.update_gbest()\n",
    "            if iter_num % self.p_interval == 0:\n",
    "                self.update_centre()\n",
    "                \n",
    "            if precision is not None:\n",
    "                tor_iter = np.amax(self.pbest_y) - np.amin(self.pbest_y)\n",
    "                if tor_iter < precision:\n",
    "                    c = c + 1\n",
    "                    if c > N:\n",
    "                        break\n",
    "                else:\n",
    "                    c = 0\n",
    "            if self.verbose and ((iter_num % (self.max_iter // 10) == 0) or (iter_num+1 == self.max_iter)):\n",
    "                print('Iter: {}, Best fit: {}'.format(iter_num, self.gbest_y))\n",
    "                # print('Iter: {}, Best fit: {} at {}'.format(iter_num, self.gbest_y, self.gbest_x))\n",
    "\n",
    "            self.gbest_y_hist.append(self.gbest_y)\n",
    "        self.best_x, self.best_y = self.gbest_x, self.gbest_y\n",
    "        return self.best_x, self.best_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Iter: 0, Best fit: [1.20792043]\n",
      "Iter: 100, Best fit: [0.06850617]\n",
      "Iter: 200, Best fit: [0.02869607]\n",
      "Iter: 300, Best fit: [0.01509811]\n",
      "Iter: 400, Best fit: [0.00996598]\n",
      "Iter: 500, Best fit: [0.00723233]\n",
      "Iter: 600, Best fit: [0.00676323]\n",
      "Iter: 700, Best fit: [0.00631957]\n",
      "Iter: 800, Best fit: [0.00592183]\n",
      "Iter: 900, Best fit: [0.00545455]\n",
      "Iter: 999, Best fit: [0.00245854]\n"
     ]
    }
   ],
   "source": [
    "pso = SGPSO(func=s_function, n_dim=len(learnable_params), pop=300, max_iter=100, lb=-2, ub=2, w=0.85, c1=1, c2=1, c3=1, data=(inp, tar), verbose=True)\n",
    "print(pso.p_interval)\n",
    "learned_params, best_loss = pso.run(max_iter=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Best fit: [0.79144832]\n",
      "Iter: 100, Best fit: [0.0150517]\n",
      "Iter: 200, Best fit: [0.00025988]\n",
      "Iter: 300, Best fit: [3.58601087e-06]\n",
      "Iter: 400, Best fit: [3.16949477e-08]\n",
      "Iter: 500, Best fit: [3.86051036e-10]\n",
      "Iter: 600, Best fit: [4.8293239e-12]\n",
      "Iter: 700, Best fit: [4.943345e-14]\n",
      "Iter: 800, Best fit: [4.69617517e-16]\n",
      "Iter: 900, Best fit: [4.32417676e-18]\n",
      "Iter: 999, Best fit: [2.69675308e-20]\n"
     ]
    }
   ],
   "source": [
    "pso = SGPSO(func=s_function, n_dim=len(learnable_params), pop=300, max_iter=100, lb=0, ub=2, w=0.85, c1=1, c2=1, c3=1, data=(inp, tar), verbose=True)\n",
    "learned_params, best_loss = pso.run(max_iter=1000, p_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect(generation=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
